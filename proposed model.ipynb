{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdbb707-5360-4c69-9558-cbb51fc36d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"D:\\ML_proj\\creditcard.csv\"  # Use raw string to handle backslashes in the path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure there are no extra spaces in the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 1. Handle missing values: Impute numerical columns with the mean, and categorical columns with the most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')  # For categorical and numerical columns\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 2. Encode categorical variables if necessary using LabelEncoder (only for categorical variables)\n",
    "label_encoder = LabelEncoder()\n",
    "for col in df.select_dtypes(include=[object]).columns:  # Only apply to categorical columns\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# 3. Feature Scaling: Standardize numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[df.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(df.select_dtypes(include=[np.number]))\n",
    "\n",
    "# 4. Check if the target variable ('Class') exists\n",
    "if \"Class\" not in df.columns:\n",
    "    raise KeyError(\"âŒ 'Class' column not found in dataset!\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"Class\"])  # All columns except 'Class'\n",
    "y = df[\"Class\"]  # 'Class' column is the target\n",
    "\n",
    "# 5. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the preprocessed dataset (optional)\n",
    "df.to_csv(r\"D:\\ML_proj\\creditcard_processed.csv\", index=False)  # Save preprocessed data\n",
    "\n",
    "print(\"Preprocessing completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81f5695e-e3ea-4b66-85b0-4dbe16e766c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87     56736\n",
      "           1       0.99      0.71      0.82     56988\n",
      "\n",
      "    accuracy                           0.85    113724\n",
      "   macro avg       0.88      0.85      0.85    113724\n",
      "weighted avg       0.88      0.85      0.85    113724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import dirichlet\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Load preprocessed dataset\n",
    "file_path = r\"D:\\ML_proj\\creditcard_processed.csv\"\n",
    "\n",
    "# Ensure correct file path and clean column names\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.strip()  # Remove extra spaces from column names\n",
    "\n",
    "# Check if 'Class' column exists\n",
    "if \"Class\" not in df.columns:\n",
    "    raise KeyError(\"âŒ 'Class' column not found in dataset! Please check the file.\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Ensure the target variable is discrete (binary classification in this case)\n",
    "# If the target is continuous, convert to binary (for example, thresholding at 0.5 for a binary classification task)\n",
    "if y.dtype != 'int64' and y.dtype != 'object':  # If the target is continuous\n",
    "    y = y.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "# Handle class imbalance using ADASYN\n",
    "adasyn = ADASYN(n_neighbors=3, random_state=42)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to generate class prior using Pitman-Yor Process (PYP)\n",
    "def pitman_yor_prior(alpha, d, num_classes):\n",
    "    base_measure = np.ones(num_classes)\n",
    "    prior_distribution = dirichlet(alpha * base_measure)\n",
    "    return prior_distribution.rvs()[0]\n",
    "\n",
    "# Self-Adaptive Bayesian Decision Tree\n",
    "class BayesianDecisionTree:\n",
    "    def __init__(self, alpha=0.5, d=0.1):\n",
    "        self.alpha = alpha  # Strength of prior\n",
    "        self.d = d  # Discount parameter\n",
    "        self.tree = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "        self.class_prior = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_classes = len(np.unique(y))\n",
    "        self.class_prior = pitman_yor_prior(self.alpha, self.d, num_classes)\n",
    "\n",
    "        # Compute class weight mapping (based on priors)\n",
    "        class_counts = np.bincount(y)\n",
    "        class_weights = {cls: self.class_prior[i] for i, cls in enumerate(np.unique(y))}\n",
    "        sample_weights = np.array([class_weights[label] for label in y])\n",
    "\n",
    "        self.tree.fit(X, y, sample_weight=sample_weights)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.tree.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.tree.predict_proba(X)\n",
    "\n",
    "# Train the Bayesian Decision Tree\n",
    "model = BayesianDecisionTree()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b925a68-eb45-45cd-a9fa-e2763aace246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Sample Model Predictions:\n",
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "451851 -0.332775 -1.885710 -1.519765 -0.708429  1.569756  5.833161 -3.549121   \n",
      "67538  -0.889231 -0.777055  0.787588  0.707614  0.534474  0.961773  0.887339   \n",
      "568304  1.565482  0.993772  0.054717 -1.682025  0.305488  0.767668 -0.127143   \n",
      "358980 -0.913241  0.512631  0.245631  0.351688  0.346108 -0.017666 -0.321067   \n",
      "374146 -0.769261 -0.739150  0.835571  0.065643  1.442747 -0.617511  0.598416   \n",
      "\n",
      "              V7        V8        V9  ...       V22        V23       V24  \\\n",
      "451851 -6.438805 -0.206824  1.394375  ... -1.422179 -19.474998 -0.722030   \n",
      "67538   0.399437  0.337275 -0.622844  ... -1.350870   0.008639 -2.999291   \n",
      "568304  0.194557 -0.073268  0.554853  ... -0.390436  -0.130421 -0.721502   \n",
      "358980  0.112549 -0.137816  0.136373  ... -0.005505  -0.244314 -0.446341   \n",
      "374146 -0.957154  0.050575 -0.547493  ...  0.767255  -0.054113 -0.318567   \n",
      "\n",
      "             V25       V26       V27       V28    Amount  True Label  \\\n",
      "451851 -5.216786 -0.433026  2.752210 -0.779710 -0.333840           1   \n",
      "67538  -0.003762 -0.741020  0.236108  0.500669 -0.349231           0   \n",
      "568304  0.547300 -0.646280  0.007346 -0.028324 -0.097488           1   \n",
      "358980  1.111387 -0.904338  0.124064  0.073381 -0.348649           1   \n",
      "374146 -0.840744  1.950178 -1.746348 -0.924824 -0.143342           1   \n",
      "\n",
      "        Predicted Label  \n",
      "451851                1  \n",
      "67538                 0  \n",
      "568304                1  \n",
      "358980                0  \n",
      "374146                1  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Select random samples from the test set for qualitative analysis\n",
    "num_samples = 5  # Adjust the number of samples as needed\n",
    "sample_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "# Extract the sample inputs using `.iloc`\n",
    "sample_inputs = X_test.iloc[sample_indices]\n",
    "sample_true_labels = y_test.iloc[sample_indices]\n",
    "\n",
    "# Predict using the trained model\n",
    "sample_predictions = model.predict(sample_inputs)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "sample_results = sample_inputs.copy()  # Copy feature values\n",
    "sample_results[\"True Label\"] = sample_true_labels.values\n",
    "sample_results[\"Predicted Label\"] = sample_predictions\n",
    "\n",
    "# Display the sample inputs and their corresponding predictions\n",
    "print(\"ðŸ“Œ Sample Model Predictions:\")\n",
    "print(sample_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16174d6-f665-45fd-9f34-e89674cdc158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90258509-9545-4e6b-845e-b4ec28d48180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
